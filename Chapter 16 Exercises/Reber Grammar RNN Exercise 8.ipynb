{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, choices\n",
    "myGraph ={\n",
    "    1 : [['T', 2], ['P', 3]],\n",
    "    2 : [['S', 2], ['X', 4]],\n",
    "    3 : [['T', 3], ['V', 5]],\n",
    "    4 : [['X', 3], ['S', 6]],\n",
    "    5 : [['P', 4], ['V', 6]],\n",
    "    6 : [['E', None]]\n",
    "}\n",
    "stopOrGo = [False, True]\n",
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "# Functions to generate random string and the reber sentences along with the labels\n",
    "def reberGrammarSentence() -> (str, int):\n",
    "    myString = \"B\"\n",
    "    currNode = 1\n",
    "    while(currNode != None):\n",
    "        edges = myGraph[currNode]\n",
    "        nextChoice = choice(edges)\n",
    "        myString += nextChoice[0]\n",
    "        currNode = nextChoice[1]\n",
    "    return myString #, 1\n",
    "\n",
    "def generateRandomString() -> str:\n",
    "    randomString = \"\"\n",
    "    while(True):\n",
    "        randomString += choice(alphabet)\n",
    "        if(choices(stopOrGo, weights=[90, 10])[0]):\n",
    "            break\n",
    "    return randomString #, 0\n",
    "\n",
    "# Aurelien's version\n",
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "def generate_corrupted_string(chars=POSSIBLE_CHARS):\n",
    "    good_string = reberGrammarSentence()\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPVPSE\n",
      "OTPYFOIHHN\n",
      "BPTTVVB\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "print(reberGrammarSentence())\n",
    "print(generateRandomString())\n",
    "print(generate_corrupted_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aurelien's encoding function\n",
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to process strings into a fixed length and pad the rest or cut off the rest\n",
    "# Straight from the book and DOES NOT WORK!!!!!\n",
    "def preprocess(batch):\n",
    "    x_batch = tf.strings.substr(batch[:,0], 0, 8)\n",
    "    x_batch = tf.strings.split(x_batch)\n",
    "    return x_batch.to_tensor(default_value=b\"<pad>\"), batch[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't even matter. \n",
    "listOfStrings = []\n",
    "for i in range(10):\n",
    "    listOfStrings.append(reberGrammarSentence())\n",
    "listOfStrings = np.asarray(listOfStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 6, 3, 1]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for encodings\n",
    "string_to_ids(reberGrammarSentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size):\n",
    "    good_strings = [string_to_ids(reberGrammarSentence())\n",
    "                    for _ in range(size // 2)]\n",
    "    bad_strings = [string_to_ids(generate_corrupted_string())\n",
    "                   for _ in range(size - size // 2)]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    # This is the only line I do not understand\n",
    "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
    "    y = np.array([[1.] for _ in range(len(good_strings))] +\n",
    "                 [[0.] for _ in range(len(bad_strings))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[0, 2, 5, 5, 1], [0, 4, 6, 6, 5, 2, 3, 1], [0, 2, 5, 5, 1], [0, 2, 5, 2, 6, 4, 5, 2, 6, 5, 5, 1], [0, 2, 5, 2, 3, 1], [0, 3, 5, 5, 1], [0, 2, 4, 3, 5, 1], [0, 2, 4, 5, 0, 1], [0, 2, 5, 4, 5, 5, 1], [3, 4, 3, 3, 6, 3, 1]]>,\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_dataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the datasets\n",
    "X_train, y_train = generate_dataset(10000)\n",
    "X_valid, y_valid = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryuparish/.local/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryuparish/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 5ms/step - loss: 0.6851 - accuracy: 0.5305 - val_loss: 0.6600 - val_accuracy: 0.5740\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.6471 - accuracy: 0.5833 - val_loss: 0.6241 - val_accuracy: 0.6410\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5866 - accuracy: 0.6854 - val_loss: 0.5152 - val_accuracy: 0.7610\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.8083 - val_loss: 0.3577 - val_accuracy: 0.8565\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.8852 - val_loss: 0.5212 - val_accuracy: 0.7960\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2491 - accuracy: 0.8986 - val_loss: 0.1572 - val_accuracy: 0.9510\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9629 - val_loss: 0.1746 - val_accuracy: 0.9515\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.0220 - val_accuracy: 0.9950\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 8.8479e-04 - accuracy: 1.0000 - val_loss: 6.8666e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.8442e-04 - accuracy: 1.0000 - val_loss: 5.3721e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7923e-04 - accuracy: 1.0000 - val_loss: 4.1498e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.1426e-04 - accuracy: 1.0000 - val_loss: 3.3547e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 2.6780e-04 - accuracy: 1.0000 - val_loss: 2.9433e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3384e-04 - accuracy: 1.0000 - val_loss: 2.5468e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0764e-04 - accuracy: 1.0000 - val_loss: 2.2249e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.8637e-04 - accuracy: 1.0000 - val_loss: 1.9702e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.6930e-04 - accuracy: 1.0000 - val_loss: 1.7803e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.5500e-04 - accuracy: 1.0000 - val_loss: 1.6567e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.4303e-04 - accuracy: 1.0000 - val_loss: 1.5246e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "embedding_size = 5\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum = 0.95, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
